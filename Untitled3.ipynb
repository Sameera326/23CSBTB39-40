{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlqMXryZXz6MhQcOagzt7o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sameera326/23CSBTB39-40/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WddWS5yJLH0j"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.datasets import load_iris\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "# Add target variable to the DataFrame\n",
        "df['target'] = iris.target\n",
        "# Identify features and target\n",
        "features = df.drop('target',axis=1)\n",
        "target = df['target']\n",
        "# Normalize the features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "features_normalized = scaler.fit_transform(features)\n",
        "features_normalized_df = pd.DataFrame(features_normalized, columns=features.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_normalized_df, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the first few rows of each dataset\n",
        "print(\"Training Features:\\n\", X_train.head())\n",
        "print(\"\\nTesting Features:\\n\", X_test.head())\n",
        "print(\"\\nTraining Target:\\n\", y_train.head())\n",
        "print(\"\\nTesting Target:\\n\", y_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc605qa_VKla",
        "outputId": "eaaa34ca-ffc1-4ccb-f4f7-f2015bdc002c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features:\n",
            "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "22           0.083333          0.666667           0.000000          0.041667\n",
            "15           0.388889          1.000000           0.084746          0.125000\n",
            "65           0.666667          0.458333           0.576271          0.541667\n",
            "11           0.138889          0.583333           0.101695          0.041667\n",
            "42           0.027778          0.500000           0.050847          0.041667\n",
            "\n",
            "Testing Features:\n",
            "      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "73            0.500000          0.333333           0.627119          0.458333\n",
            "18            0.388889          0.750000           0.118644          0.083333\n",
            "118           0.944444          0.250000           1.000000          0.916667\n",
            "78            0.472222          0.375000           0.593220          0.583333\n",
            "76            0.694444          0.333333           0.644068          0.541667\n",
            "\n",
            "Training Target:\n",
            " 22    0\n",
            "15    0\n",
            "65    1\n",
            "11    0\n",
            "42    0\n",
            "Name: target, dtype: int64\n",
            "\n",
            "Testing Target:\n",
            " 73     1\n",
            "18     0\n",
            "118    2\n",
            "78     1\n",
            "76     1\n",
            "Name: target, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Convert categorical variables to dummy variables\n",
        "df_encoded = pd.get_dummies(df_filled, drop_first=True)\n",
        "# Normalize the features using Min-Max scaling\n",
        "scaler = MinMaxScaler()\n",
        "features_normalized = scaler.fit_transform(df_encoded.drop('Survived', axis=1))\n",
        "features_normalized_df = pd.DataFrame(features_normalized, columns=df_encoded.drop('Survived', axis=1).columns)\n",
        "\n",
        "print(\"\\nNormalized Features:\\n\", features_normalized_df.head())\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_normalized_df, target, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\nTraining Features:\\n\", X_train.head())\n",
        "print(\"\\nTesting Features:\\n\", X_test.head())\n",
        "print(\"\\nTraining Target:\\n\", y_train.head())\n",
        "print(\"\\nTesting Target:\\n\", y_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "5w0Y7bC-cCAw",
        "outputId": "d9c16f54-b37a-4779-efa6-a2015db83220"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_filled' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-3385668a7c46>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Convert categorical variables to dummy variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_filled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Normalize the features using Min-Max scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_filled' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#question 2\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Load the Titanic dataset from seaborn's repository\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
        "# Describe the dataset\n",
        "df_description = df.describe(include='all')\n",
        "print(\"Dataset Description:\\n\", df_description)\n",
        "# Data types of each column\n",
        "data_types = df.dtypes\n",
        "print(\"\\nData Types:\\n\", data_types)\n",
        "\n",
        "# Shape of the dataset\n",
        "data_shape = df.shape\n",
        "print(\"\\nShape of the Dataset:\", data_shape)\n",
        "# Assuming 'Survived' is the target variable\n",
        "target = df['Survived']\n",
        "features = df.drop(['Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "print(\"\\nFeatures:\\n\", features.head())\n",
        "print(\"\\nTarget:\\n\", target.head())\n",
        "# Check for null values\n",
        "null_values = df.isnull().sum()\n",
        "print(\"\\nNull Values:\\n\",null_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPOslKoHXqp6",
        "outputId": "2670e2c0-ddce-45ea-98d0-6856486c9b4b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Description:\n",
            "         PassengerId    Survived      Pclass                     Name   Sex  \\\n",
            "count    891.000000  891.000000  891.000000                      891   891   \n",
            "unique          NaN         NaN         NaN                      891     2   \n",
            "top             NaN         NaN         NaN  Braund, Mr. Owen Harris  male   \n",
            "freq            NaN         NaN         NaN                        1   577   \n",
            "mean     446.000000    0.383838    2.308642                      NaN   NaN   \n",
            "std      257.353842    0.486592    0.836071                      NaN   NaN   \n",
            "min        1.000000    0.000000    1.000000                      NaN   NaN   \n",
            "25%      223.500000    0.000000    2.000000                      NaN   NaN   \n",
            "50%      446.000000    0.000000    3.000000                      NaN   NaN   \n",
            "75%      668.500000    1.000000    3.000000                      NaN   NaN   \n",
            "max      891.000000    1.000000    3.000000                      NaN   NaN   \n",
            "\n",
            "               Age       SibSp       Parch  Ticket        Fare    Cabin  \\\n",
            "count   714.000000  891.000000  891.000000     891  891.000000      204   \n",
            "unique         NaN         NaN         NaN     681         NaN      147   \n",
            "top            NaN         NaN         NaN  347082         NaN  B96 B98   \n",
            "freq           NaN         NaN         NaN       7         NaN        4   \n",
            "mean     29.699118    0.523008    0.381594     NaN   32.204208      NaN   \n",
            "std      14.526497    1.102743    0.806057     NaN   49.693429      NaN   \n",
            "min       0.420000    0.000000    0.000000     NaN    0.000000      NaN   \n",
            "25%      20.125000    0.000000    0.000000     NaN    7.910400      NaN   \n",
            "50%      28.000000    0.000000    0.000000     NaN   14.454200      NaN   \n",
            "75%      38.000000    1.000000    0.000000     NaN   31.000000      NaN   \n",
            "max      80.000000    8.000000    6.000000     NaN  512.329200      NaN   \n",
            "\n",
            "       Embarked  \n",
            "count       889  \n",
            "unique        3  \n",
            "top           S  \n",
            "freq        644  \n",
            "mean        NaN  \n",
            "std         NaN  \n",
            "min         NaN  \n",
            "25%         NaN  \n",
            "50%         NaN  \n",
            "75%         NaN  \n",
            "max         NaN  \n",
            "\n",
            "Data Types:\n",
            " PassengerId      int64\n",
            "Survived         int64\n",
            "Pclass           int64\n",
            "Name            object\n",
            "Sex             object\n",
            "Age            float64\n",
            "SibSp            int64\n",
            "Parch            int64\n",
            "Ticket          object\n",
            "Fare           float64\n",
            "Cabin           object\n",
            "Embarked        object\n",
            "dtype: object\n",
            "\n",
            "Shape of the Dataset: (891, 12)\n",
            "\n",
            "Features:\n",
            "    PassengerId  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
            "0            1       3    male  22.0      1      0   7.2500        S\n",
            "1            2       1  female  38.0      1      0  71.2833        C\n",
            "2            3       3  female  26.0      0      0   7.9250        S\n",
            "3            4       1  female  35.0      1      0  53.1000        S\n",
            "4            5       3    male  35.0      0      0   8.0500        S\n",
            "\n",
            "Target:\n",
            " 0    0\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: Survived, dtype: int64\n",
            "\n",
            "Null Values:\n",
            " PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n"
          ]
        }
      ]
    }
  ]
}